{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 채널 별 mean 계산\n",
    "def get_mean(dataset):\n",
    "  meanRGB = [np.mean(image.numpy(), axis=(1,2)) for image,_ in dataset]\n",
    "  meanR = np.mean([m[0] for m in meanRGB])\n",
    "  meanG = np.mean([m[1] for m in meanRGB])\n",
    "  meanB = np.mean([m[2] for m in meanRGB])\n",
    "  return [meanR, meanG, meanB]\n",
    "\n",
    "# 채널 별 str 계산\n",
    "def get_std(dataset):\n",
    "  stdRGB = [np.std(image.numpy(), axis=(1,2)) for image,_ in dataset]\n",
    "  stdR = np.mean([s[0] for s in stdRGB])\n",
    "  stdG = np.mean([s[1] for s in stdRGB])\n",
    "  stdB = np.mean([s[2] for s in stdRGB])\n",
    "  return [stdR, stdG, stdB]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dir\n",
    "os.makedirs('./data/train', exist_ok=True)\n",
    "os.makedirs('./data/test', exist_ok=True)\n",
    "#import dataset\n",
    "train_dataset = datasets.STL10('./data/train', split='train',download=True,\n",
    "                               transform=transforms.ToTensor())\n",
    "test_dataset = datasets.STL10('./data/test', split='test',download=True,\n",
    "                               transform=transforms.ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data transform\n",
    "train_transforms = transforms.Compose([transforms.Resize((128,128)),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(get_mean(train_dataset),\n",
    "                                                            get_std(train_dataset))])\n",
    "test_transforms = transforms.Compose([transforms.Resize((128,128)),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(get_mean(test_dataset),\n",
    "                                                            get_std(test_dataset))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainsform 정의\n",
    "train_dataset.transform = train_transforms\n",
    "test_dataset.transform = test_transforms\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True).to(device)\n",
    "unpretrained_model = models.resnet50(pretrained=False)\n",
    "block = models.resnet.BasicBlock  # BasicBlock 블록 선택\n",
    "models.ResNet(block, layers=[3,4,6,3])\n",
    "\n",
    "lr = 0.0001\n",
    "num_epochs = 5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer)\n",
    "loss_function = nn.CrossEntropyLoss().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {\n",
    "'num_epochs':num_epochs,\n",
    "'optimizer':optimizer,\n",
    "'loss_function':loss_function,\n",
    "'train_dataloader':train_dataloader,\n",
    "'test_dataloader': test_dataloader,\n",
    "'device':device\n",
    "}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, params):\n",
    "    loss_function=params[\"loss_function\"]\n",
    "    train_dataloader=params[\"train_dataloader\"]\n",
    "    test_dataloader=params[\"test_dataloader\"]\n",
    "    device=params[\"device\"]\n",
    "\n",
    "    for epoch in range(0, num_epochs):\n",
    "        for i, data in enumerate(train_dataloader, 0):\n",
    "            # train dataloader 로 불러온 데이터에서 이미지와 라벨을 분리\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # 이전 batch에서 계산된 가중치를 초기화\n",
    "            optimizer.zero_grad() \n",
    "\n",
    "            # forward + back propagation 연산\n",
    "            outputs = model(inputs)\n",
    "            train_loss = loss_function(outputs, labels)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # test accuracy 계산\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        accuracy = []\n",
    "        for i, data in enumerate(test_dataloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # 결과값 연산\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            test_loss = loss_function(outputs, labels).item()\n",
    "            accuracy.append(100 * correct/total)\n",
    "\n",
    "        # 학습 결과 출력\n",
    "        print('Epoch: %d/%d, Train loss: %.6f, Test loss: %.6f, Accuracy: %.2f' %(epoch+1, num_epochs, train_loss.item(), test_loss, 100*correct/total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, params)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
